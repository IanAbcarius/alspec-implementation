# alspec-implementation
This repository contains a GPU implementation of attention level speculation to reduce LLM inference latency. Additional sections include a testbench, demo interface, and backend server.
